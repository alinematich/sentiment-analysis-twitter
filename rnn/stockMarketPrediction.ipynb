{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    81348\n",
       " 2    63777\n",
       " 0    41912\n",
       "-2    25351\n",
       " 1    10588\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine sentiment by stanford\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('sentiment_tweet.csv', quotechar='\"')\n",
    "del df['text']\n",
    "del df['Unnamed: 0']\n",
    "del df['Unnamed: 0.1']\n",
    "del df['user']\n",
    "\n",
    "import ast\n",
    "\n",
    "def getSent(row):\n",
    "    sentiment = ast.literal_eval(row['sentiment'])['sentiment']\n",
    "    stanford = row['stanford']\n",
    "    if stanford == 1:\n",
    "        stanford = 1\n",
    "    if stanford == -1:\n",
    "        stanford = -1\n",
    "    if stanford == 2:\n",
    "        stanford = 1\n",
    "    if stanford == -2:\n",
    "        stanford = -1\n",
    "    if sentiment == None:\n",
    "        return stanford\n",
    "    else:\n",
    "        if sentiment['basic'] == 'Bullish':\n",
    "            return 2\n",
    "        if sentiment['basic'] == 'Bearish':\n",
    "            return -2\n",
    "        return stanford\n",
    "    \n",
    "df['sentiment'] = df.apply(getSent, axis=1)\n",
    "del df['stanford']\n",
    "df.head()\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by date\n",
    "def getIndex(arr):\n",
    "    bull = 0\n",
    "    bear = 0\n",
    "    for i in arr:\n",
    "        if i > 0:\n",
    "            bull += i\n",
    "        if i < 0:\n",
    "            bear += -i\n",
    "#     return bull-bear\n",
    "    if bull == bear:\n",
    "        return 0\n",
    "    elif bull > bear:\n",
    "        return ((2*bull)/(bull+bear) - 1) / len(arr)\n",
    "    else:\n",
    "        return (1 - (2*bear)/(bull+bear)) / len(arr)\n",
    "\n",
    "data = df.groupby('date').agg({'sentiment': getIndex})['sentiment']\n",
    "data.to_csv('aggregate_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add time series to sentiment\n",
    "import datetime as dt\n",
    "df = pd.read_csv(\"./AAP_data.csv\", usecols=[0,1,2,3,4,5])\n",
    "df['date'] = df['date'].map(lambda x: dt.datetime.strptime(x,\"%Y-%m-%d\").strftime('%Y.%m.%d'))\n",
    "\n",
    "data = pd.read_csv('./aggregate_tweet.csv', header=None, names = ['date', 'sentiment'])\n",
    "data = data.set_index('date')\n",
    "df = df.set_index('date')\n",
    "result = pd.concat([data, df], axis=1, join='inner')\n",
    "result.to_csv('./merged_result.csv')\n",
    "result = pd.read_csv('./merged_result.csv', usecols=[1,5,6])\n",
    "result.head()\n",
    "\n",
    "result['output'] = result.close.shift(-1)    \n",
    "\n",
    "result.dropna(inplace=True)\n",
    "result.reset_index(drop=True,inplace=True)\n",
    "try:\n",
    "    result = result.drop(columns=['date'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630564</td>\n",
       "      <td>0.301822</td>\n",
       "      <td>0.303628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.847330</td>\n",
       "      <td>0.626455</td>\n",
       "      <td>0.181174</td>\n",
       "      <td>0.271155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.779408</td>\n",
       "      <td>0.617696</td>\n",
       "      <td>0.141735</td>\n",
       "      <td>0.369706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.852223</td>\n",
       "      <td>0.623049</td>\n",
       "      <td>0.153678</td>\n",
       "      <td>0.201238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864224</td>\n",
       "      <td>0.604279</td>\n",
       "      <td>0.232292</td>\n",
       "      <td>0.299457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment     close    volume    output\n",
       "0   0.000000  0.630564  0.301822  0.303628\n",
       "1   0.847330  0.626455  0.181174  0.271155\n",
       "2   0.779408  0.617696  0.141735  0.369706\n",
       "3   0.852223  0.623049  0.153678  0.201238\n",
       "4   0.864224  0.604279  0.232292  0.299457"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess dataframe\n",
    "up = 1\n",
    "down = -1\n",
    "def setLabel(row):\n",
    "    yesterday = row['close']\n",
    "    today = row['output']\n",
    "#     return today\n",
    "    return today - yesterday\n",
    "    if yesterday < today:\n",
    "        return up\n",
    "    if today < yesterday:\n",
    "        return down\n",
    "    return 0\n",
    "\n",
    "result['output'] = result.apply(setLabel, axis=1)\n",
    "\n",
    "def norm(a):\n",
    "    b = a - a.min()\n",
    "    return b / b.max()\n",
    "\n",
    "result['sentiment'] = norm(result['sentiment'])\n",
    "result['output'] = norm(result['output'])\n",
    "result['close'] /= result['close'].max()\n",
    "result['volume'] /= result['volume'].max()\n",
    "result.to_csv('./ML_cols.csv', encoding='utf-8')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 6s - loss: 0.0151\n",
      "Epoch 2/30\n",
      " - 2s - loss: 0.0113\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.0126\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.0117\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.0128\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.0095\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.0098\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.0089\n",
      "Epoch 9/30\n",
      " - 4s - loss: 0.0115\n",
      "Epoch 10/30\n",
      " - 4s - loss: 0.0100\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.0100\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.0089\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.0091\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.0096\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.0097\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.0091\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.0105\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.0093\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.0091\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.0087\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.0093\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.0089\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.0092\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.0091\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.0092\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.0087\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.0091\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.0081\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.0090\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93d443f390>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dropout, Activation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def create_dataset1(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = []\n",
    "        for j in range(look_back):\n",
    "            a += dataset[i+j, :-1].tolist()\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, -1])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(look_back-1, len(dataset)):\n",
    "        a = []\n",
    "        for j in range(look_back):\n",
    "            a += dataset[i-j, :-1].tolist()\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i, -1])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "numpy.random.seed(7)\n",
    "\n",
    "dataframe = pd.read_csv('./ML_cols.csv', usecols=[1,2,3,4])\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "look_back = 2\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# trainX = x_scaler.fit_transform(trainX)\n",
    "# trainY  = y_scaler.fit_transform(trainY.reshape(-1,1))\n",
    "# testX = x_scaler.transform(testX)\n",
    "# testY = y_scaler.transform(testY.reshape(-1,1))\n",
    "\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(3 * look_back, trainX.shape[2]), return_sequences=True, units=50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=30, batch_size=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.09 RMSE\n",
      "\n",
      "0.27115458 0.31478444\n",
      "0.3697064 0.31914535\n",
      "0.20123753 0.31863683\n",
      "0.2994565 0.31953016\n",
      "0.4807885 0.31990346\n",
      "0.34138933 0.31983858\n",
      "0.36896887 0.3206736\n",
      "0.42941162 0.3206293\n",
      "0.08223556 0.32006925\n",
      "0.33156705 0.32047957\n",
      "0.42941162 0.32074523\n",
      "0.4044796 0.32023084\n",
      "0.16307929 0.31983626\n",
      "0.27339363 0.32032788\n",
      "0.39994478 0.31973302\n",
      "0.28661227 0.31935194\n",
      "0.31872284 0.31965947\n",
      "0.18272384 0.31923604\n",
      "0.3262796 0.32039595\n",
      "0.3984357 0.32016012\n",
      "0.30172202 0.32030463\n",
      "0.24883604 0.32087785\n",
      "0.27868107 0.3206346\n",
      "0.39881012 0.32007647\n",
      "0.3855877 0.31951147\n",
      "0.36594692 0.3197288\n",
      "0.5348091 0.31983155\n",
      "0.45170367 0.32067904\n",
      "0.26092383 0.32115537\n",
      "0.37500897 0.32035923\n",
      "0.34441507 0.31994468\n",
      "0.31456625 0.31996435\n",
      "0.37916937 0.31998777\n",
      "0.31230074 0.31967854\n",
      "0.35725552 0.3196913\n",
      "0.37727827 0.319755\n",
      "0.34138933 0.3207694\n",
      "0.39692283 0.3204643\n",
      "0.39541376 0.32011\n",
      "0.2684806 0.32046044\n",
      "0.29870006 0.31959242\n",
      "0.3610339 0.31966084\n",
      "0.27679 0.32003763\n",
      "0.3636814 0.3200564\n",
      "0.1880113 0.32047153\n",
      "0.63152283 0.32398486\n",
      "0.40485403 0.32508114\n",
      "0.3225012 0.32252318\n",
      "0.29643455 0.32166556\n",
      "0.50496787 0.321477\n",
      "0.33572367 0.3210265\n",
      "0.3217448 0.32179707\n",
      "0.39163536 0.32158852\n",
      "0.3338326 0.3211439\n",
      "0.35650286 0.3208725\n",
      "0.31192252 0.32123637\n",
      "0.39503554 0.32217845\n",
      "0.37085617 0.32163227\n",
      "0.36669958 0.3206381\n",
      "0.29606012 0.32082433\n",
      "0.3632994 0.32109573\n",
      "0.470588 0.32095313\n",
      "0.37312546 0.32164207\n",
      "0.334589 0.32260758\n",
      "0.36481228 0.32184434\n",
      "0.3474408 0.32107708\n",
      "0.30775458 0.3212552\n",
      "0.27261072 0.3215872\n",
      "0.32476673 0.3220263\n",
      "0.23065518 0.32072383\n",
      "0.35991436 0.3211723\n",
      "0.35462314 0.32122126\n",
      "0.29452834 0.32098535\n",
      "0.34404063 0.3207094\n",
      "0.36444917 0.3198632\n",
      "0.381832 0.31994194\n",
      "0.47518334 0.3206358\n",
      "0.32098457 0.3214868\n",
      "0.27298892 0.32142094\n",
      "0.3213628 0.32063857\n",
      "0.35311025 0.32038957\n",
      "0.3447933 0.3208512\n",
      "0.35537955 0.32007584\n",
      "0.32060635 0.32020676\n",
      "0.46082246 0.3211584\n",
      "0.30586725 0.32189462\n",
      "0.40753558 0.3222332\n",
      "0.1558251 0.3209524\n",
      "0.35046652 0.32054228\n",
      "0.381832 0.3210069\n",
      "0.2593807 0.32102734\n",
      "0.36369276 0.32074612\n",
      "0.35311025 0.32006574\n",
      "0.2763891 0.31994152\n",
      "0.46497905 0.3202852\n",
      "0.3859886 0.32055765\n",
      "0.34819722 0.32076025\n",
      "0.3345928 0.3207184\n",
      "0.3795665 0.32101947\n",
      "0.38447952 0.32103664\n",
      "0.27789816 0.32080364\n",
      "0.27525446 0.3215434\n",
      "0.75901574 0.32187206\n",
      "0.40413162 0.3257904\n",
      "0.38750148 0.32723722\n",
      "0.3410149 0.3236816\n",
      "0.37465346 0.32319772\n",
      "0.30624548 0.3226205\n",
      "0.35424492 0.3228414\n",
      "0.42794034 0.32274544\n",
      "0.37389702 0.32248986\n",
      "0.2423761 0.3223557\n",
      "0.3368583 0.3223197\n",
      "0.38750148 0.32291752\n",
      "0.26580662 0.32279265\n",
      "0.4166052 0.32253343\n",
      "0.5382963 0.32259005\n",
      "0.23859772 0.32326445\n",
      "0.3406367 0.3235157\n",
      "0.3345928 0.32272506\n",
      "0.3190935 0.32244578\n",
      "0.34404063 0.32255152\n",
      "0.32703224 0.32264078\n",
      "0.31834084 0.32293466\n",
      "0.28394586 0.3229519\n",
      "0.25862807 0.32286587\n",
      "0.489166 0.32298926\n",
      "0.40602273 0.3231827\n",
      "0.3327017 0.3234017\n",
      "0.2903566 0.32314077\n",
      "0.30245575 0.32365745\n",
      "0.31984615 0.32370993\n",
      "0.4083185 0.3226329\n",
      "0.3497139 0.3224611\n",
      "0.2771266 0.32267106\n",
      "0.38033804 0.32305378\n",
      "0.28695267 0.32320857\n",
      "0.30207753 0.3228523\n",
      "0.26087087 0.32265052\n",
      "0.3368583 0.32228518\n",
      "0.42797816 0.3223977\n",
      "0.3523576 0.322536\n",
      "0.11606701 0.32273424\n",
      "0.25179747 0.32283726\n",
      "0.48657522 0.32294723\n",
      "0.40075415 0.32325307\n",
      "0.38676393 0.32274902\n",
      "0.0 0.32251263\n",
      "0.4310001 0.3239614\n",
      "0.41323152 0.32392517\n",
      "0.34895745 0.3233945\n",
      "0.30207753 0.32376584\n",
      "0.15122977 0.32352942\n",
      "0.48317125 0.32322317\n",
      "acc:  None\n",
      "\n",
      "\n",
      "\n",
      "Test Score: 0.15 RMSE\n",
      "\n",
      "0.34442264 0.32378235\n",
      "0.33610564 0.32418972\n",
      "0.13534847 0.3234585\n",
      "0.47409785 0.3234733\n",
      "0.38865504 0.32364273\n",
      "0.33648387 0.32280356\n",
      "0.44499034 0.32309374\n",
      "0.423814 0.3231893\n",
      "0.40567097 0.323154\n",
      "0.28430894 0.3236096\n",
      "0.17655513 0.32399228\n",
      "1.0 0.32369933\n",
      "0.06616137 0.32636023\n",
      "0.38411644 0.32782507\n",
      "0.33837494 0.32447684\n",
      "0.27712283 0.3235005\n",
      "0.09716376 0.3232764\n",
      "0.451038 0.32289207\n",
      "0.42948726 0.32277462\n",
      "0.3504741 0.3223107\n",
      "0.39092433 0.32199034\n",
      "0.32022434 0.3226344\n",
      "0.28393072 0.32323265\n",
      "0.33383635 0.32349375\n",
      "0.3391276 0.32351428\n",
      "0.3436662 0.32387906\n",
      "0.24045098 0.3239801\n",
      "0.02343806 0.32418975\n",
      "0.2786395 0.3231332\n",
      "0.31833327 0.32289267\n",
      "0.3769379 0.3231559\n",
      "0.30623415 0.32300904\n",
      "0.23742904 0.32350793\n",
      "0.14555652 0.32271156\n",
      "0.30963808 0.3225296\n",
      "0.2521719 0.32270953\n",
      "0.1976785 0.3226356\n",
      "0.2910979 0.3229838\n",
      "acc:  None\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "trainCorrect = trainY\n",
    "testCorrect = testY\n",
    "# trainPredict = y_scaler.inverse_transform(trainPredict)\n",
    "# trainCorrect = y_scaler.inverse_transform(trainY)\n",
    "# testPredict = y_scaler.inverse_transform(testPredict)\n",
    "# testCorrect = y_scaler.inverse_transform(testY)\n",
    "import math\n",
    "\n",
    "def sign(a):\n",
    "    if a>0:\n",
    "        return 1\n",
    "    if a<0:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def acc(a, b):\n",
    "    cnt = 0\n",
    "    for i in range(len(a)):\n",
    "        print(a[i], b[i])\n",
    "        if sign(a[i]) == sign(b[i]):\n",
    "            cnt += 1\n",
    "    return\n",
    "    return cnt / len(a)\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainCorrect[:], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "print()\n",
    "print(\"acc: \", acc((trainCorrect[:]), (trainPredict[:,0])))\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "testScore = math.sqrt(mean_squared_error(testCorrect[:], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "print()\n",
    "print(\"acc: \", acc((testCorrect[:]), (testPredict[:,0])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
